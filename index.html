<!DOCTYPE html>
<html lang="it">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>IsoSign Contest CAIP 2025</title>
  <link rel="stylesheet" href="css/styles.css" />
</head>

<body>
  <div id="frontespizio">
    <div style="
          display: flex;
          justify-content: center;
          align-items: center;
          gap: 20px;
          margin-bottom: 1.5rem;
        ">
      <a href="https://www.uniba.it/it" target="_blank">
        <img src="img/loghi/uniba/uniba_logo_w.svg" alt="Logo UNIBA" style="height: 100px" /></a>
      <a href="https://cilab.di.uniba.it" target="_blank">
        <img src="img/loghi/cilab/cilab_logo_w.svg" alt="Logo CILAB" style="height: 100px" /></a>
      <a href="https://caip2025.com" target="_blank">
        <img src="img/loghi/caip/LOGO-CAIP-2025.png" alt="Logo CAIP" style="height: 50px" /></a>
    </div>
    <h1 class="glitch-text" data-text="IsoSign Contest 2025">
      IsoSign Contest 2025
    </h1>
    <h2 style="color: #fff; font-size: 1.5rem; margin-top: 1rem">
      21th International Conference on Computer Analysis of Images and Patterns - CAIP 2025
    </h2>
    <p style="
          color: #ccc;
          font-size: 1rem;
          max-width: 600px;
          text-align: center;
          margin: 1rem auto;
        ">
      QUI HO BISOGNO DI TE RINOOOOO!
    </p>
  </div>
  <header style="
        display: flex;
        justify-content: space-between;
        align-items: center;
        background: #333;
        color: #fff;
        padding: 1rem;
      ">
    <h1 style="margin: 0">IsoSign Contest 2025</h1>
    <nav>
      <ul style="list-style: none; display: flex; margin: 0; padding: 0">
        <li style="margin-right: 10px">
          <a href="#contest" style="color: #fff; text-decoration: none">Contest</a>
        </li>
        <li style="margin-right: 10px">
          <a href="#dataset" style="color: #fff; text-decoration: none">Dataset</a>
        </li>
        <li style="margin-right: 10px">
          <a href="#protocollo" style="color: #fff; text-decoration: none">Evaluation protocol</a>
        </li>
        <li style="margin-right: 10px">
          <a href="#regole" style="color: #fff; text-decoration: none">Rules</a>
        </li>
        <li style="margin-right: 10px">
          <a href="#istruzioni" style="color: #fff; text-decoration: none">Instructions</a>
        </li>
        <li style="margin-right: 10px">
          <a href="#organizzatori" style="color: #fff; text-decoration: none">Organizers</a>
        </li>
        <li>
          <a href="#contatti" style="color: #fff; text-decoration: none">Contact</a>
        </li>
      </ul>
    </nav>
  </header>

  <section id="contest">
    <div style="max-width: 1400px; margin: 0 auto;">
      <h2>Contest</h2>
      <div style="display: flex; flex-direction: row; align-items: flex-start; gap: 20px; height: fit-content;">
        <div style="flex: 1; min-width: 60%;">
          <p>
            Sign language recognition represents a formidable challenge in computer
            vision due to the complex spatiotemporal dynamics of gestures and the
            need for precise segmentation in continuous video streams. Many current
            methods struggle with reliably partitioning continuous signing into
            individual glosses or mapping these segments into text. In this contest,
            participants will leverage a novel isolated Italian Sign Language
            dataset to train robust models. In isolated sign language recognition,
            each sign is presented individually, without context, similar to
            flashcards used for learning new words in spoken language. In contrast,
            continuous sign language recognition mirrors real-life communication,
            where signs transition seamlessly from one to the next, forming
            structured expressions much like spoken sentences. The IsoSign Contest
            is a competition among methods for sign language recognition using
            transfer learning. For the contest, we propose the use of a novel
            training set, IsoSignLanguage Dataset, completely annotated with
            corresponding transcription and glossary. The performance of the
            competing methods will be evaluated in terms of accuracy on a private
            test set composed by images that are different from the ones available
            in the training set, in fact the objective is to transfer learning from
            isolated training data to continuous test data.
          </p>
        </div>
        <div style="flex: 1; min-width: 30%; display: flex; align-items: flex-start; justify-content: center;">
          <img src="img/test_grid.png" alt="Test Dataset Example" style="width: 75%; height: auto;">
        </div>
      </div>
    </div>
  </section>

  <section id="dataset">
    <div style="max-width: 1400px; margin: 0 auto;">
      <h2>Dataset</h2>
      <div style="display: flex; flex-direction: row; align-items: flex-start; gap: 20px;">
        <div style="flex: 2; min-width: 60%;">
          <p>The IsolatedLIS Dataset consists of 16,856 videos about signer of Italian language annotated with the following labels:</p>
          <ul>
            <li>Text: the associated word in Italian Sign Language (LIS).</li>
            <li>Category: the category of the word (e.g., sport-tempo-libero, lingua, baby-sign, etc.)</li>
            <li>Gloss: the gloss of the word in Italian, created by a semi-supervised method.</li>
            <li>Frame_count: the number of frames in the video.</li>
            <li>Video_Path: the path of the video.</li>
          </ul>
          <p>Since the images are collected in different conditions, the dataset is heterogeneous in terms of size, illumination, pose of the person, and distance from the camera. Each image of the dataset contains a single person. We make available to the participants two folders with the training and validation videos and a JSON file for each set with the labels of the samples.</p>
          <p>Since the goal of this contest is the development of research on pedestrian attributes recognition, we encourage participants to use other samples or to add missing labels for training their models, if such additional samples and annotations are made publicly available. The diffusion of samples annotated with pedestrian attributes would make a great contribution to the development of this line of research and to the realization of real applications in this field.</p>
        </div>
      </div>
      <div style="flex: 1; min-width: 30%; display: flex; align-items: flex-start; justify-content: center;">
        <img src="img/train_set.png" alt="Training Dataset Examples" style="max-width: 90%; height: auto;">
      </div>
    </div>
  </section>

  <section id="protocollo">
    <h2>Evaluation Protocol</h2>
    <p>To ensure a fair and rigorous assessment of the submitted models, the SignRec Contest 2025 employs multiple evaluation metrics, primarily focusing on Word Error Rate (WER), a standard measure for sequence-based recognition tasks. Sign Accuracy (SA) and Boundary Segmentation Score (BSS) are also introduced to evaluate different aspects of model performance.</p>
  
    <h3>Word Error Rate (WER)</h3>
    <p>Word Error Rate is the primary evaluation metric, quantifying the accuracy of the recognized sign sequences compared to the ground truth annotations. It is computed as:</p>
    <p><code>WER = (S + D + I) / N = (S + D + I) / (S + D + C)</code></p>
    <ul>
      <li><strong>S</strong>: Number of substitutions (incorrectly recognized signs).</li>
      <li><strong>D</strong>: Number of deletions (missed signs).</li>
      <li><strong>I</strong>: Number of insertions (extra signs detected).</li>
      <li><strong>C</strong>: Number of correctly recognized signs.</li>
      <li><strong>N</strong>: Total number of signs in the ground truth sentence (<code>N = S + D + C</code>).</li>
    </ul>
    <p>Lower WER values indicate better recognition performance, as fewer errors are introduced in the predicted sign sequences.</p>
  
    <h3>Sign Accuracy (SA)</h3>
    <p>Sign Accuracy measures the percentage of correctly predicted signs within a sequence, providing a complementary metric to WER. It is defined as:</p>
    <p><code>SA = (C / N) × 100</code></p>
    <p>Here, <strong>C</strong> represents the number of correctly predicted signs. Unlike WER, SA does not penalize insertions, making it helpful in evaluating raw recognition accuracy.</p>
  
    <h3>Boundary Segmentation Score (BSS)</h3>
    <p>To assess the ability of models to segment continuous signing into discrete glosses, we introduce the Boundary Segmentation Score (BSS), which measures the alignment of predicted sign boundaries with ground truth annotations. It is calculated based on precision and recall, evaluating how well the system detects the start and end points of individual signs in continuous sequences:</p>
    <p><code>BSS = (2 × P × R) / (P + R)</code></p>
    <ul>
      <li><strong>Precision (P)</strong>: Measures how many predicted boundaries are correct.</li>
      <li><strong>Recall (R)</strong>: Measures how many actual boundaries were correctly detected.</li>
    </ul>
    <p>A higher BSS indicates better temporal segmentation performance, critical for accurate continuous sign recognition.</p>
  </section>

  <section id="regole">
    <h2>Rules</h2>
    <ol>
      <li>
        The deadline for the submission of the methods is
        <strong>30th June, 2025</strong>. The submission must be done with an
        email in which the participants share (directly or with external
        links) the trained model, the code, and the report. Please follow the
        detailed instructions reported <a href="#istruzioni">here</a>.
      </li>
      <li>
        The participants can receive the training set and the annotations by
        sending an email to the organizer, in which they also communicate the
        name of the team.
      </li>
      <li>
        The participants can use these training and validation samples and
        annotations, but they can also use additional samples and/or add the
        missing labels, under the constraint that they make the additional
        samples and annotations publicly available.
      </li>
      <li>
        The participants are free to design novel architectures or to define
        novel training procedure and loss functions for classifiers or
        regressors.
      </li>
      <li>
        The participants must submit their trained model and their code by
        carefully following the detailed instructions reported
        <a href="#istruzioni">here</a>.
      </li>
      <li>
        The participants are strongly encouraged to submit a contest paper to
        <a href="https://caip2025.com/call-for-papers/">CAIP 2025</a>, whose
        deadline is 10th July, 2025. The contest paper must be also sent by
        email to the organizers. Otherwise, the participants must produce a
        brief PDF report of the proposed method, by following a template that
        can be downloaded
        <a
          href="https://docs.google.com/document/d/1LEnYuY24BE_vJrb_AqgCJwgUlV68xfY5vFi9K5ykxBo/edit?usp=sharing">here</a>.
        If you submit a paper, you can cite the paper describing the
        contest by downloading the <a href="">bibtex file</a> or as follows: [Citazione
        paper]
      </li>
      <li>
        Participants must produce a brief PDF report of the proposed method,
        by following a template that can be downloaded
        <a href="https://drive.google.com/file/d/12-bsPJCg_NoorGSkRAJrsbx8V1L6L8Nt/view?usp=sharing">here</a>.
      </li>
    </ol>
  </section>

  <section id="istruzioni">
    <h2>Instructions</h2>
    <p>The methods proposed by the participants will be executed on a private test set. To leave the participants
      totally free to use all the software libraries they prefer and to correctly reproduce their processing pipeline,
      the evaluation will be done on Google Colab (follow this tutorial) by running the code submitted by the
      participants on the samples of our private test set.
    </p>
    <p>
      Therefore, the partecipants must submit an archive (download an example) including the following elements:
    </p>
    <ol>
      <ul>
        A Python script <code>test.py</code>, which takes as inputs a json file tiwh the same format of the training
        annotations (<code>--data</code>) and the folder of the test videos (<code>--videos</code>) and procedures as
        output a CSV file with the predicted sign for each video (<code>--results</code>). Thus, the script may be
        executed with teh following command:
        <p><code>python test.py --data foo_test.csv --videos foo_test/ --results foo_results.csv</code></p>
      </ul>
      <ul>
        A Google Colab Notebook <code>test.ipynb</code>, which includes the commands for installing all software
        requirements and executes the scripts <code>test.py</code>
      </ul>
      <ul>
        All the files necessary for running the test, namely the training model, additional scripts and so on.
      </ul>
    </ol>
    <p>
      The provided sample <code>test.py</code> also includes the reading of the CSV file with the annotations. Each raw
      of the file includes, separared by a comma (according to the CSV standard), the filename of the sample (e.g.
      000001.png) and the estimated sign (e.g. 1,4,6,19,4,1,5). Therefore, an example of raw may be
      000001.png,1,4,6,19,4,1,5.
      The file of the results will be formatted exactly in the same way. The provided sample <code>test.py</code>
      includes the writing of the results file.
    </p>
    <p>The submission must be done by <a href="mailto:emanuele.colonna@uniba.it">email</a>
      . The archive file can be attached to the e-mail or shared with external
      links. We strongly recommend to follow the example of code to prepare the submission.
    </p>
    <p>
      The participants are strongly encouraged to submit a contest paper to <a
        href="https://caip2025.com/call-for-papers/">CAIP 2025</a>, whose deadline is 10th July,
      2025. The contest paper must be also sent by <a href="mailto:emanuele.colonna@uniba.it">email</a> to the
      organizers. If you submit a paper, you can cite the
      paper describing the contest by downloading the bibtex file or as follows:
    <ul>Colonna E., ........ Online available here</ul>
    </p>
  </section>
  <section id="organizzatori" style="text-align: center; padding: 2rem;">
    <h2>Organizers</h2>
    <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 20px;">
      <!-- Organizer 1 -->
      <div style="max-width: 300px; text-align: center;">
        <img src="img/organizers/giovanna.jpg" alt="Organizer 1" style="width: 100%; border-radius: 10px;" />
        <h3>Giovanna Castellano</h3>
        <p style="color: #666; margin: 0.1rem 0;">Full Professor</p>
        <p style="color: #666; margin: 0.1rem 0;">Department of Computer Science (CILab)</p>
        <p style="color: #666; margin: 0.1rem 0;">University of Study Aldo Moro Bari, Italy</p>
        <div style="display: flex; justify-content: center; gap: 10px; margin-top: 10px;">
          <a href="https://linkedin.com/in/organizer3" target="_blank">
            <img src="img/social/linkedin.png" alt="LinkedIn" style="width: 20px;" />
          </a>
          <a href="https://scholar.google.com/citations?user=organizer1" target="_blank">
            <img src="img/social/gscholar.png" alt="Google Scholar" style="width: 20px" />
          </a>
          <a href="https://github.com/organizer3" target="_blank">
            <img src="img/social/github.png" alt="GitHub" style="width: 20px;" />
          </a>
        </div>
      </div>

      <!-- Organizer 2 -->
      <div style="max-width: 300px; text-align: center;">
        <img src="img/organizers/emanuele.jpeg" alt="Organizer 2" style="width: 100%; border-radius: 10px;" />
        <h3>Emanuele Colonna</h3>
        <p style="color: #666; margin: 0.1rem 0;">PhD Student</p>
        <p style="color: #666; margin: 0.1rem 0;">Department of Computer Science (CILab)</p>
        <p style="color: #666; margin: 0.1rem 0;">University of Study Aldo Moro Bari, Italy</p>
        <div style="display: flex; justify-content: center; gap: 10px; margin-top: 10px;">
          <a href="https://linkedin.com/in/organizer3" target="_blank">
            <img src="img/social/linkedin.png" alt="LinkedIn" style="width: 20px;" />
          </a>
          <a href="https://scholar.google.com/citations?user=organizer1" target="_blank">
            <img src="img/social/gscholar.png" alt="Google Scholar" style="width: 20px" />
          </a>
          <a href="https://github.com/organizer3" target="_blank">
            <img src="img/social/github.png" alt="GitHub" style="width: 20px;" />
          </a>
        </div>
      </div>

      <!-- Organizer 3 -->
      <div style="max-width: 300px; text-align: center;">
        <img src="img/organizers/gennaro.jpg" alt="Organizer 3" style="width: 100%; border-radius: 10px;" />
        <h3>Gennaro Vessio</h3>
        <p style="color: #666; margin: 0.1rem 0;">Dottor</p>
        <p style="color: #666; margin: 0.1rem 0;">Department of Computer Science (CILab)</p>
        <p style="color: #666; margin: 0.1rem 0;">University of Study Aldo Moro Bari, Italy</p>
        <div style="display: flex; justify-content: center; gap: 10px; margin-top: 10px;">
          <a href="https://linkedin.com/in/organizer3" target="_blank">
            <img src="img/social/linkedin.png" alt="LinkedIn" style="width: 20px;" />
          </a>
          <a href="https://scholar.google.com/citations?user=organizer1" target="_blank">
            <img src="img/social/gscholar.png" alt="Google Scholar" style="width: 20px" />
          </a>
          <a href="https://github.com/organizer3" target="_blank">
            <img src="img/social/github.png" alt="GitHub" style="width: 20px;" />
          </a>
        </div>
      </div>
    </div>
  </section>

  <section id="contatti" style="display: flex; flex-wrap: wrap; justify-content: center; align-items: flex-start;">
    <h1>Contact</h2>
      <div style="flex: 1; max-width: 100px;">
        <h2>Contact Info</h2>
        <p><strong>Email:</strong> emanuele.colonna@uniba.it</p>
        <p><strong>Phone:</strong> +39 327 3768534</p>
      </div>
      <form action="mailto:emanuele.colonna@uniba.it" method="post" enctype="text/plain"
        style="max-width: 600px; margin: 0 auto;">
        <label for="name" style="display: block; margin-bottom: 0.5rem;">Name:</label>
        <input type="text" id="name" name="name" required style="width: 100%; padding: 0.5rem; margin-bottom: 1rem;" />

        <label for="email" style="display: block; margin-bottom: 0.5rem;">Email:</label>
        <input type="email" id="email" name="email" required
          style="width: 100%; padding: 0.5rem; margin-bottom: 1rem;" />

        <label for="subject" style="display: block; margin-bottom: 0.5rem;">Subject:</label>
        <input type="text" id="subject" name="subject" required
          style="width: 100%; padding: 0.5rem; margin-bottom: 1rem;" />

        <label for="message" style="display: block; margin-bottom: 0.5rem;">Message:</label>
        <textarea id="message" name="message" rows="5" required
          style="width: 100%; padding: 0.5rem; margin-bottom: 1rem;"></textarea>

        <button type="submit"
          style="background-color: #333; color: #fff; padding: 0.5rem 1rem; border: none; cursor: pointer;">
          Send
        </button>
      </form>
  </section>

  <footer>
    <p>&copy; 2025 Nome del Contest. Tutti i diritti riservati.</p>
  </footer>

  <script src="js/script.js"></script>
</body>

</html>